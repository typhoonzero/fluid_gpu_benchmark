apiVersion: batch/v1
kind: Job
metadata:
  name: lm-multi-pserver
spec:
  parallelism: 4
  completions: 4
  template:
    metadata:
      labels:
        paddle-job-pserver: lm-multi
    spec:
      hostNetwork: true
      restartPolicy: Never
      volumes:
        - name: nvidia-driver
          hostPath:
            path: /usr/local/nvidia/lib64
      imagePullSecrets:
      - name: job-registry-secret
      containers:
      - name: pserver
        #image: "registry.baidu.com/paddlepaddle/fluid_benchmark:gpu"
        image: "bootstrapper:5000/fluid_benchmark:gpu"
        imagePullPolicy: Always
        volumeMounts:
          - mountPath: /usr/local/nvidia/lib64
            name: nvidia-driver
        ports:
        - name: jobport-30260
          containerPort: 30260
        env:
        - name: PADDLE_JOB_NAME
          value: lm-multi
        - name: MKL_NUM_THREADS
          value: "1"
        - name: TRAINING_ROLE
          value: "PSERVER"
        - name: TRAINERS
          value: "4"
        - name: PSERVERS
          value: "4"
        - name: TOPOLOGY
          value: ""
        - name: GLOG_v
          value: "2"
        - name: GLOG_logtostderr
          value: "1"
        - name: LOCAL
          value: "FALSE"
        - name: BATCH_SIZE
          value: "5"
        - name: IS_SPARSE
          value: "FALSE"
        - name: ENTRY
          value: "unset http_proxy && unset https_proxy && cd /workspace/lm && python gru_lm_multi.py"
        - name: TRAINER_PACKAGE
          value: "/workspace"
        - name: PADDLE_INIT_PORT
          value: "30260"
        - name: PADDLE_INIT_NICS
          value: "eth2"
        - name: PADDLE_INIT_TRAINER_COUNT
          value: "1"
        - name: PADDLE_INIT_PORTS_NUM
          value: "1"
        - name: PADDLE_INIT_PORTS_NUM_FOR_SPARSE
          value: "1"
        - name: PADDLE_INIT_NUM_GRADIENT_SERVERS
          value: "4"
        - name: PADDLE_INIT_NUM_PASSES
          value: "1"
        - name: PADDLE_INIT_USE_GPU
          value: "0"
        - name: LD_LIBRARY_PATH
          value: "/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/cuda/lib64"
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: "status.podIP"
        command: ["paddle_k8s", "start_fluid"]
        #command: ["sleep", "3600"]
        resources:
          requests:
            memory: 30Gi
            cpu: 1
            #alpha.kubernetes.io/nvidia-gpu: 1
          limits:
            memory: 30Gi
            cpu: 1
            #alpha.kubernetes.io/nvidia-gpu: 1
